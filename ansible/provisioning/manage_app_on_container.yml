# Start an app on a container
- hosts: nodes
  become: no
  gather_facts: no

  vars_files:
    - vars/main.yml
    - config/config.yml

  vars:
    - container_bind_dir: "{{ bind_dir }}/{{ container }}"
    - hdfs_file_list: ["core-site.xml", "hdfs-site.xml", "hadoop-env.sh", "rack_topology.py"]
    - hadoop_file_list: ["yarn-site.xml", "mapred-site.xml", "yarn-env.sh"]
    - spark_file_list: ["spark-defaults.conf"]

  environment:
    BDWATCHDOG_PATH: "{{ bdwatchdog_path }}"
    RESCALING_PATH: "{{ serverless_containers_path }}/scripts/"
    PYTHONPATH: ":{{ serverless_containers_path }}"

  ## Singularity + cgroups v1
  tasks:
  ## Setup network
  ## TODO: maybe setup a DNS server is better
  ## TODO: setup iptables
  - name: Setup network on containers
    block:
      - name: Get containers IP addresses
        shell: "{% for item in containers_info %}
          {% if item.host == inventory_hostname %}
          sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \"printf '%s ' \\$(hostname -I | awk '{print \\$2}') && hostname\" && 
          {% endif  %}
          {% endfor %}true"
        args:
          executable: /bin/bash
        register: ip_addresses

      - name: Update hostname resolution in containers
        shell: "{% for item in containers_info %}
          {% if item.host == inventory_hostname %}
          sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
          'cp /etc/hosts {{ bind_dir_on_container }} \
          && {% for host_ip in resolution_list.split('\n') | select() %}sed -i '\\''1s/^/{{ host_ip }}\\n/'\\'' {{ bind_dir_on_container }}/hosts && {% endfor %}true \
          && cat {{ bind_dir_on_container }}/hosts > /etc/hosts \
          && rm {{ bind_dir_on_container }}/hosts' && 
          {% endif  %}
          {% endfor %}true"
        args:
          executable: /bin/bash
        vars:
          iface_ip_list: "{{ ansible_play_hosts | map('extract', hostvars, 'ip_addresses') | list }}"
          resolution_list: "{% for result in iface_ip_list | flatten(levels=1) %}{{ result.stdout }}\n{% endfor %}"

      # Iptables setup ready, but i'll leave it commented in case it interferes with hadoop/yarn tests
      # - name: Setup Iptables (1)
      #   when: item.host == inventory_hostname
      #   shell: "sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
      #     'iptables-nft -P FORWARD DROP \
      #     && iptables-nft -P INPUT DROP \
      #     && iptables-nft -A INPUT -m state --state INVALID -j DROP \
      #     && iptables-nft -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT \
      #     && iptables-nft -A INPUT -i lo -j ACCEPT'"
      #   args:
      #     executable: /bin/bash
      #   loop: "{{ containers_info }}"

      # - name: Setup Iptables (2)
      #   when: item[0].host == inventory_hostname
      #   shell: "sudo {{ singularity_command_alias }} exec instance://{{ item[0].container_name }} bash -c \
      #     'iptables-nft -A INPUT -s {{ item[1].stdout | trim }} -j ACCEPT'"
      #   args:
      #     executable: /bin/bash
      #   vars:
      #     iface_ip_list: "{{ ansible_play_hosts | map('extract', hostvars, 'ip_addresses') | map(attribute='results') }}"
      #   loop: "{{ containers_info | product(iface_ip_list | flatten(levels=1) | reject('search','skip_reason'))|list }}"

    vars:
      - containers_info: "{{ containers_info_str | replace('\n','') | replace(' ','') }}"
    tags: never, setup_network

  - name: Setup connection on containers with global hdfs
    block:
      - name: Get global namenode IP address
        when: inventory_hostname == global_namenode_host
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ global_namenode_container }} bash -c \"printf '%s ' \\$(hostname -I | awk '{print \\$2}') && hostname\""
        args:
          executable: /bin/bash
        register: global_namenode_resolution

      - name: Update hostname resolution in containers
        when: inventory_hostname == rm_host
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} bash -c \
          'cp /etc/hosts {{ bind_dir_on_container }} \
          && sed -i '\\''1s/^/{{ namenode_iface_ip }}\\n/'\\'' {{ bind_dir_on_container }}/hosts \
          && cat {{ bind_dir_on_container }}/hosts > /etc/hosts \
          && rm {{ bind_dir_on_container }}/hosts'"
        args:
          executable: /bin/bash
        vars:
          namenode_iface_ip: "{{ (ansible_play_hosts | map('extract', hostvars, 'global_namenode_resolution') | first).stdout }}"
    tags: never, setup_global_hdfs_connection

  - name: Setup hadoop on containers
    block:
      - name: Workers file setup
        tags: setup_hadoop, setup_hdfs
        block:
          - name: get the user id running the deploy
            become: no
            local_action: command id -u
            register: userid_on_the_host

          - name: Copy app files already on containers & Update workers file on containers
            shell: "{% for item in containers_info %}
              {% if item.host == inventory_hostname %}
              sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \ 
              'cp -pr /opt/files_dir {{ bind_dir_on_container }}/ && chown -R {{ userid_on_the_host.stdout }} {{ bind_dir_on_container }}/* \
              && {% for item in worker_list %}echo {{ item }} >> $HADOOP_CONF_DIR/workers && {% endfor %}true' && 
              {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash
            vars:
              worker_list: "{{ containers_info | 
                      map(attribute='container_name') |
                      reject('search', rm_container) | list}}"

      - name: Prepare and copy all config files to containers
        tags: setup_hadoop
        block:
          - name: Copy hdfs config files to master
            delegate_to: localhost
            run_once: yes
            template:
              src: "templates/hadoop/{{ item }}"
              dest: "{{ tmpdir }}/{{ item }}"
              mode: preserve
            loop: "{{ hdfs_file_list }}"
            tags: setup_hdfs

          - name: Copy hadoop config files to master
            delegate_to: localhost
            run_once: yes
            template:
              src: "templates/hadoop/{{ item }}"
              dest: "{{ tmpdir }}/{{ item }}"
            loop: "{{ hadoop_file_list }}"

          - name: Copy spark config files to master
            when: app_type is defined and app_type == 'spark_app'
            delegate_to: localhost
            run_once: yes
            template:
              src: "templates/spark/{{ item }}"
              dest: "{{ tmpdir }}/{{ item }}"
            loop: "{{ spark_file_list }}"

          - name: Copy config files to hosts
            synchronize:
              src: "{{ tmpdir }}/"
              dest: "{{ tmpdir }}/"
            tags: setup_hdfs

          - name: Copy and update hdfs config files to containers
            shell: "{% for item in containers_info %}
              {% if item.host == inventory_hostname %}
              {% for file in hdfs_file_list %}
              {% set bind_dir = item.disk_path + '/' + bind_dir_name if item.disk_path is defined else default_bind_path + '/' + bind_dir_name %}
              cp {{ tmpdir }}/{{ file }} {{ bind_dir }}/{{ item.container_name }}/{{ file }} && 
              {% endfor %}
              sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
              '{% for file in hdfs_file_list %}cp {{ bind_dir_on_container }}/{{ file }} $HADOOP_CONF_DIR/{{ file }} && {% endfor %}true' && 
              {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash
            tags: setup_hdfs

          - name: Copy and update hadoop config files to containers
            shell: "{% for item in containers_info %}
              {% if item.host == inventory_hostname %}
              {% for file in hadoop_file_list %}
              {% set bind_dir = item.disk_path + '/' + bind_dir_name if item.disk_path is defined else default_bind_path + '/' + bind_dir_name %}
              cp {{ tmpdir }}/{{ file }} {{ bind_dir }}/{{ item.container_name }}/{{ file }} && 
              {% endfor %}
              sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
              '{% for file in hadoop_file_list %}cp {{ bind_dir_on_container }}/{{ file }} $HADOOP_CONF_DIR/{{ file }} && {% endfor %}true' && 
              {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash

          - name: Copy and update spark config files to containers
            when: app_type is defined and app_type == 'spark_app'
            shell: "{% for item in containers_info %}
              {% if item.host == inventory_hostname %}
              {% for file in spark_file_list %}
              {% set bind_dir = item.disk_path + '/' + bind_dir_name if item.disk_path is defined else default_bind_path + '/' + bind_dir_name %}
              cp {{ tmpdir }}/{{ file }} {{ bind_dir }}/{{ item.container_name }}/{{ file }} && 
              {% endfor %}
              sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
              '{% for file in spark_file_list %}cp {{ bind_dir_on_container }}/{{ file }} $SPARK_CONF_DIR/{{ file }} && {% endfor %}true' && 
              {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash

      - name: Setup SSH connection
        tags: setup_hadoop, setup_hdfs
        block:
          - name: Update ssh known_hosts on ResourceManager/Namenode container & Move RM/NN container ssh public key
            when: rm_host == inventory_hostname
            shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} bash -c \
              'ssh-keyscan -t rsa `hostname` >> ~/.ssh/known_hosts \
              && ssh-keyscan -t rsa -f $HADOOP_CONF_DIR/workers >> ~/.ssh/known_hosts \
              && cp ~/.ssh/id_rsa.pub {{ bind_dir_on_container }}/{{ rm_container }}.pub'"
            args:
              executable: /bin/bash

          ## TODO: fusion with fetch below
          - name: Prepare RM/NN container bind path variable
            when: "item.container_name == rm_container"
            set_fact:
              rm_container_bind_path: "{{ item.disk_path if item.disk_path is defined else default_bind_path }}"
            with_items:
            - "{{ containers_info }}"

          - name: Create app directory on server for ssh public key
            delegate_to: localhost
            run_once: yes
            file:
              path: "{{ installation_path }}/apps/{{ app_name }}/"
              state: directory

          - name: Fetch RM/NN container ssh public key
            when: rm_host == inventory_hostname
            synchronize:
              src: "{{ bind_dir }}/{{ rm_container }}/{{ rm_container }}.pub"
              dest: "{{ installation_path }}/apps/{{ app_name }}/{{ rm_container }}.pub"
              mode: pull
            vars:
              bind_path: "{{ rm_container_bind_path }}"

          - name: Create app directory on hosts for ssh public key
            file:
              path: "{{ installation_path }}/apps/{{ app_name }}/"
              state: directory

          - name: Copy RM/NN container ssh public key to hosts
            synchronize:
              src: "{{ installation_path }}/apps/{{ app_name }}/{{ rm_container }}.pub"
              dest: "{{ installation_path }}/apps/{{ app_name }}/{{ rm_container }}.pub"

          - name: Copy and append RM/NN container ssh public key to the other containers
            shell: "{% for item in containers_info %}
              {% if item.host == inventory_hostname and item.container_name != rm_container %}
              {% set bind_dir = item.disk_path + '/' + bind_dir_name if item.disk_path is defined else default_bind_path + '/' + bind_dir_name %}
              cp {{ installation_path }}/apps/{{ app_name }}/{{ rm_container }}.pub {{ bind_dir }}/{{ item.container_name }}/{{ rm_container }}.pub && \
              sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
              'cat {{ bind_dir_on_container }}/{{ rm_container }}.pub >> ~/.ssh/authorized_keys \
              && rm {{ bind_dir_on_container }}/{{ rm_container }}.pub' && 
              {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash

      - name: Start HDFS + YARN
        tags: setup_hadoop
        block:
          - name: Format filesystem, start HDFS and YARN (Master)
            when: rm_host == inventory_hostname
            shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} bash -c \
              '(cd $HADOOP_HOME \
              && bash format_filesystem.sh) \
              && (nohup $HADOOP_HOME/bin/hdfs --daemon start namenode & \
              nohup $HADOOP_HOME/bin/yarn --daemon start resourcemanager &)'"
            args:
              executable: /bin/bash

          - name: Start HDFS and YARN (Worker)
            shell: "{% for item in containers_info %}
              {% if item.host == inventory_hostname and item.container_name != rm_container %}
              sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
              'nohup $HADOOP_HOME/bin/hdfs --daemon start datanode & \
              nohup $HADOOP_HOME/bin/yarn --daemon start nodemanager &' && 
              {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash

      - name: Start only HDFS
        tags: setup_hdfs
        block:
          - name: Format filesystem and start HDFS (Master)
            when: rm_host == inventory_hostname
            shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} bash -c \
              '(cd $HADOOP_HOME \
              && bash format_filesystem.sh) \
              && (nohup $HADOOP_HOME/bin/hdfs --daemon start namenode &)'"
            args:
              executable: /bin/bash

          - name: Start HDFS (Worker)
            shell: "{% for item in containers_info %}
              {% if item.host == inventory_hostname and item.container_name != rm_container %}
              sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
              'nohup $HADOOP_HOME/bin/hdfs --daemon start datanode &' && 
              {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash

      - name: Wait some seconds for Namenode to exit safe mode
        tags: setup_hadoop, setup_hdfs
        pause:
          seconds: 10
    vars:
      - containers_info: "{{ containers_info_str | replace('\n','') | replace(' ','') }}"
    tags: never

  ## Start
  - name: Start app on container
    block:
      - name: get the user id running the deploy
        become: no
        local_action: command id -u
        register: userid_on_the_host

      - name: Copy app files already on container if there was an installation
        when: "install_script != ''"
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c 'cp -pr /opt/{{ app_dir }}/* {{ bind_dir_on_container }} && chown -R {{ userid_on_the_host.stdout }} {{ bind_dir_on_container }}/*'"
        args:
          executable: /bin/bash

      # - name: Check if app files directory is already there
      #   when: "files_dir != ''"
      #   stat:
      #     path: "{{ container_bind_dir }}/{{ files_dir | basename }}"
      #     get_checksum: false
      #     get_mime: false
      #     get_attributes: false
      #   register: stat_output
      #   tags: stop_app

      - block:
          - name: Create app files directory
            file:
              path: "{{ container_bind_dir }}/{{ files_dir | basename }}"
              state: directory

          - name: Find config files to template in the app directory
            delegate_to: localhost
            run_once: yes
            find:
              paths: "apps/{{ app_dir }}/{{ files_dir }}/"
              recurse: yes
            register: found_config_files

          - name: Process template for each config file
            template:
              src: "{{ item.path }}"
              dest: "{{ container_bind_dir }}/{{ files_dir | basename }}/{{ item.path | basename}}"
            loop: "{{ found_config_files.files }}"
        when: "files_dir != ''"
        tags: stop_app

      - name: Copy app start script
        template:
          src: "apps/{{ app_dir }}/{{ start_script }}"
          dest: "{{ container_bind_dir }}/"
          mode: preserve

      - name: Copy app jar
        when: "app_jar != ''"
        synchronize:
          src: "apps/{{ app_dir }}/{{ app_jar }}"
          dest: "{{ container_bind_dir }}/"

      - name: Execute start script on container
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} nohup bash {{ bind_dir_on_container }}/{{ start_script | basename }} </dev/null"
        args:
          executable: /bin/bash

    tags: never, start_app

  ## Stop
  - name: Stop app on container
    block:
      - block:
        - name: Copy app stop script
          template:
            src: "apps/{{ app_dir }}/{{ stop_script }}"
            dest: "{{ container_bind_dir }}/"
            mode: preserve

        - name: Execute stop script on container
          shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} nohup bash {{ bind_dir_on_container }}/{{ stop_script | basename }} </dev/null"
          args:
            executable: /bin/bash
        when: stop_script is defined and stop_script != ""

      - name: Remove app files
        when: item != ""
        file:
          path: "{{ container_bind_dir }}/{{ item | basename }}"
          state: absent
        with_items:
          - "{{ install_script if install_script is defined else '' }}"
          - "{{ start_script if start_script is defined else '' }}"
          - "{{ stop_script if stop_script is defined else '' }}"
          - "{{ app_jar if app_jar is defined else '' }}"

      - name: Remove hadoop config files
        when: "app_jar != ''"
        file:
          path: "{{ container_bind_dir }}/{{ item }}"
          state: absent
        loop: "{{ hdfs_file_list + hadoop_file_list + spark_file_list }}"

      - name: Remove container own ssh key
        file:
          path: "{{ container_bind_dir }}/{{ container }}.pub"
          state: absent

      - name: Remove container from container-PID mapping
        delegate_to: localhost
        run_once: yes
        when: "power_budgeting"
        lineinfile:
          path: "{{ containers_pid_mapping_file }}"
          regexp: "^{{ container }}"
          create: yes
          state: absent

      # Stop java snitcher
      - name: Stop java snitcher
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c \
          'tmux kill-session -t JAVA_SNITCH'"
        args:
          executable: /bin/bash
        ignore_errors: yes

      - name: Remove hadoop files directory in container
        # Check empty string to avoid unwanted problems if the variable is somehow wrongly defined
        when: "app_jar != '' and ' ' not in bind_dir_on_container"
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c \
          'rm -r {{ bind_dir_on_container}}/files_dir'"
        args:
          executable: /bin/bash

      - name: get the user id running the deploy
        become: no
        local_action: command id -u
        register: userid_on_the_host

      # Workaround to avoid having result files root-owned
      # TODO: move results to another directory accesible for the user
      - name: Change remaining files permissions
        # Check empty string to avoid unwanted problems if the variable is somehow wrongly defined
        when: "' ' not in userid_on_the_host.stdout"
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c \
          'cd {{ bind_dir_on_container }} \
          && chown -R {{ userid_on_the_host.stdout }} *output* | : \
          && chown -R {{ userid_on_the_host.stdout }} output_* | : \
          && chown {{ userid_on_the_host.stdout }} runtime_* | : \
          && chown {{ userid_on_the_host.stdout }} app_log_* | : \
          && chown {{ userid_on_the_host.stdout }} datagen_log_* | :'"
        args:
          executable: /bin/bash

      - name: Change remaining files permissions (hadoop)
        # Check empty string to avoid unwanted problems if the variable is somehow wrongly defined
        when: "app_jar != '' and ' ' not in userid_on_the_host.stdout"
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c \
          'cd {{ bind_dir_on_container }} \
          && chown -R {{ userid_on_the_host.stdout }} hadoop_logs'"
        args:
          executable: /bin/bash

      # TODO: actually transfer files from nodes to server, instead of relying on shared folders (NFS and such)
      - name: Copy hadoop logs to server node
        when: "app_jar != '' and input_dir != output_dir"
        copy:
          src: "{{ input_dir }}"
          dest: "{{ output_dir }}"
          remote_src: yes
        vars:
          input_dir: "{{ container_bind_dir }}/hadoop_logs/"
          output_dir: "{{ default_bind_path }}/{{ bind_dir_name }}/{{ rm_container }}/hadoop_logs/"

      - name: Remove hadoop local logs
        when: "app_jar != '' and input_dir != output_dir"
        file:
          path: "{{ input_dir }}"
          state: absent
        vars:
          input_dir: "{{ container_bind_dir }}/hadoop_logs"
          output_dir: "{{ default_bind_path }}/{{ bind_dir_name }}/{{ rm_container }}/hadoop_logs"

      - name: Remove app files directory
        when: "files_dir != ''"
        file:
          path: "{{ container_bind_dir }}/{{ files_dir | basename }}"
          state: absent

    tags: never, stop_app

  ## Stop hadoop
  - name: Stop hadoop cluster
    block:
      - name: Stop hadoop cluster
        when: rm_host == inventory_hostname
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} bash -c \
          'cd $HADOOP_HOME \
          && sbin/stop-yarn.sh \
          && sbin/stop-dfs.sh'"
        args:
          executable: /bin/bash
    tags: never, stop_hadoop_cluster

  # TODO: do not rely on shared folders (NFS and such) to access hadoop_logs
  ## Set hadoop logs timestamp
  - name: Set hadoop logs timestamp
    delegate_to: localhost
    run_once: yes
    shell: "mv hadoop_logs hadoop_logs_`date +%d-%m-%y--%H-%M-%S`"
    args:
      chdir: "{{ default_bind_path }}/{{ bind_dir_name }}/{{ rm_container }}"
      executable: /bin/bash
    tags: never, set_hadoop_logs_timestamp

  ## TODO: Remove app_jar conditions in these tasks (in the whole file)


  ## HDFS
  - name: Create directory on HDFS
    when: dest_path is defined and dest_path != ''
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c '$HADOOP_HOME/bin/hdfs dfs -mkdir -p {{ dest_path }}'"
    args:
      executable: /bin/bash
    tags: never, create_dir_on_hdfs

  - name: Remove file from HDFS
    when: dest_path is defined and dest_path != ''
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c '$HADOOP_HOME/bin/hdfs dfs -rm -r {{ dest_path }}'"
    args:
      executable: /bin/bash
    tags: never, remove_file_from_hdfs

  - name: Upload file(s) to HDFS
    tags: never, add_file_to_hdfs
    when: dest_path is defined and dest_path != '' and origin_path is defined and origin_path != ''
    vars:
      container_tmp_path: "{{ container_bind_dir }}/{{ origin_path.rstrip('/') | basename }}"
      container_bind_tmp_path: "{{ bind_dir_on_container }}/{{ origin_path.rstrip('/') | basename }}"
      starting_origin_dir: hdfs_data
    block:
      - name: Copy data to namenode container
        synchronize:
          src: "{{ starting_origin_dir }}/{{ origin_path }}"
          dest: "{{ container_tmp_path }}"
          perms: true

      - name: Put data on HDFS
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c '$HADOOP_HOME/bin/hdfs dfs -put {{ container_bind_tmp_path }} {{ dest_path }}'"
        args:
          executable: /bin/bash

      - name: Clean data on namenode container
        file:
          path: "{{ container_tmp_path }}"
          state: absent

  - name: Download file(s) from HDFS
    tags: never, get_file_from_hdfs
    when: dest_path is defined and origin_path is defined and origin_path != ''
    vars:
      container_tmp_path: "{{ container_bind_dir }}/{{ origin_path | basename }}"
      starting_dest_dir: hdfs_data
    block:
      - name: get the user id running the deploy
        become: no
        local_action: command id -u
        register: userid_on_the_host

      - name: Get data from HDFS
        when: "' ' not in userid_on_the_host.stdout"
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c \ 
          '$HADOOP_HOME/bin/hdfs dfs -get {{ origin_path }} {{ bind_dir_on_container }} \ 
          && chown -R {{ userid_on_the_host.stdout }} {{ bind_dir_on_container }}/{{ origin_path | basename }}'"
        args:
          executable: /bin/bash

      - name: Copy data from namenode container to server
        synchronize:
          src: "{{ container_tmp_path }}"
          dest: "{{ starting_dest_dir }}/{{ dest_path.rstrip('/') }}/"
          perms: true
          mode: pull

      - name: Clean data on namenode container
        file:
          path: "{{ container_tmp_path }}"
          state: absent


  - name: Move data between global and local HDFS
    tags: never
    when: inventory_hostname == rm_host
    vars:
      global_namenode_ip: "\\$(getent hosts {{ global_namenode_container }} | awk '{print \\$1 }')" ## for some reason distcp does not resolve hostnames, so this workaround is needed to resolve ip before executing distcp
      global_namenode_url: "hdfs://{{ global_namenode_ip }}:8020"
    block:
      - name: Download data from global HDFS to local one
        tags: download_to_local
        when: global_input is defined and global_input != '' and local_output is defined and local_output != ''
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} bash -c \"\\$HADOOP_HOME/bin/hadoop distcp {{ origin }} {{ dest }}\""
        args:
          executable: /bin/bash
        vars:
          origin: "{{ global_namenode_url }}/{{ global_input }}"
          dest: "{{ local_output }}/{{ global_input | basename }}"

      - name: Upload data from local HDFS to global one
        tags: upload_to_global
        when: local_input is defined and local_input != '' and global_output is defined and global_output != ''
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} bash -c \"\\$HADOOP_HOME/bin/hadoop distcp {{ origin }} {{ dest }}\""
        args:
          executable: /bin/bash
        vars:
          origin: "{{ local_input }}"
          dest: "{{ global_namenode_url }}/{{ global_output }}/{{ local_input | basename }}"
