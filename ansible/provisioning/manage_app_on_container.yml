# Start an app on a container
- hosts: nodes
  become: no
  gather_facts: no

  vars_files:
    - vars/main.yml
    - config/config.yml

  vars:
    - jid_file: "{{ ansible_async_dir }}/{{ container }}.jid"
    - singularity_env_file: "/.singularity.d/env/90-environment.sh"
    - container_bind_dir: "{{ [bind_dir, container] | join('/') if container is defined }}"
    - hdfs_file_list: ["core-site.xml", "hdfs-site.xml", "hadoop-env.sh", "rack_topology.py", "hdfs-rbf-site.xml"]
    - hadoop_file_list: ["yarn-site.xml", "mapred-site.xml", "yarn-env.sh"]
    - spark_file_list: ["spark-defaults.conf"]
    - app_tmpdir: "{{ tmpdir }}/{{ app_name }}"

  environment:
    BDWATCHDOG_PATH: "{{ bdwatchdog_path }}"
    RESCALING_PATH: "{{ serverless_containers_path }}/scripts/"
    PYTHONPATH: ":{{ serverless_containers_path }}"

  ## Singularity + cgroups v1

  tasks:
  - import_tasks: tasks/utils/get_user_ids.yml
    tags: always

  ## Setup network
  ## TODO: maybe setup a DNS server is better
  ## TODO: setup iptables
  - name: Setup network on containers
    block:
      - name: Get containers IP addresses
        shell: "{% for item in containers_info %}
          {% if item.host == inventory_hostname %}
          sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} su - {{ user_info.user_name }} -c \ 
            {% if not 'expose_ptp' in item %}\"printf '%s ' \\$(hostname -I | awk '{print \\$1}') && hostname\" &&
            {% else %}\"printf '%s ' \\$(hostname -I | awk '{print \\$2}') && hostname\" &&
            {% endif %}
          {% endif  %}
          {% endfor %}true"
        args:
          executable: /bin/bash
        register: ip_addresses

      - name: Update hostname resolution in containers
        shell: "{% for item in containers_info %}
          {% if item.host == inventory_hostname %}
          sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
          'cp /etc/hosts {{ user_home_on_container }} \
          && {% for host_ip in resolution_list.split('\n') | select() %}sed -i '\\''1s/^/{{ host_ip }}\\n/'\\'' {{ user_home_on_container }}/hosts && {% endfor %}true \
          && cat {{ user_home_on_container }}/hosts > /etc/hosts \
          && rm {{ user_home_on_container }}/hosts' &&
          {% endif  %}
          {% endfor %}true"
        args:
          executable: /bin/bash
        vars:
          iface_ip_list: "{{ ansible_play_hosts | map('extract', hostvars, 'ip_addresses') | list }}"
          resolution_list: "{% for result in iface_ip_list | flatten(levels=1) %}{{ result.stdout }}\n{% endfor %}"

      # Iptables setup ready, but i'll leave it commented in case it interferes with hadoop/yarn tests
      # - name: Setup Iptables (1)
      #   when: item.host == inventory_hostname
      #   shell: "sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \
      #     'iptables-nft -P FORWARD DROP \
      #     && iptables-nft -P INPUT DROP \
      #     && iptables-nft -A INPUT -m state --state INVALID -j DROP \
      #     && iptables-nft -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT \
      #     && iptables-nft -A INPUT -i lo -j ACCEPT'"
      #   args:
      #     executable: /bin/bash
      #   loop: "{{ containers_info }}"

      # - name: Setup Iptables (2)
      #   when: item[0].host == inventory_hostname
      #   shell: "sudo {{ singularity_command_alias }} exec instance://{{ item[0].container_name }} bash -c \
      #     'iptables-nft -A INPUT -s {{ item[1].stdout | trim }} -j ACCEPT'"
      #   args:
      #     executable: /bin/bash
      #   vars:
      #     iface_ip_list: "{{ ansible_play_hosts | map('extract', hostvars, 'ip_addresses') | map(attribute='results') }}"
      #   loop: "{{ containers_info | product(iface_ip_list | flatten(levels=1) | reject('search','skip_reason'))|list }}"

    vars:
      - containers_info: "{{ containers_info_str | replace('\n','') | replace(' ','') }}"
    tags: never, setup_network

  - name: Setup connection on global hdfs with containers
    block:
      - name: Get containers IP addresses for cross-resolution
        when: inventory_hostname == item.host
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ item.container }} su - {{ user_info.user_name }} -c \"printf '%s ' \\$(hostname -I | awk '{print \\${{ item.ip_position }}}') && hostname\""
        args:
          executable: /bin/bash
        loop:
          - { container: "{{ rm_container }}",            host: "{{ rm_host }}",       ip_position: 1 }
          - { container: "{{ namenode_container_name }}", host: "{{ namenode_host }}", ip_position: "{{ '2' if server_as_host else '1' }}" }
        register: container_resolutions

      - name: Update hostname resolution in containers
        when: inventory_hostname == item.host
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ item.container }} bash -c \
          'cp /etc/hosts {{ user_home_on_container }} \
          && sed -i '\\''1s/^/{{ iface_ip_dict[item.container] }}\\n/'\\'' {{ user_home_on_container }}/hosts \
          && cat {{ user_home_on_container }}/hosts > /etc/hosts \
          && rm {{ user_home_on_container }}/hosts'"
        args:
          executable: /bin/bash
        loop:
          - { container: "{{ namenode_container_name }}", host: "{{ namenode_host }}" }
          - { container: "{{ rm_container }}",            host: "{{ rm_host }}" }
        vars:
          iface_ip_list:
            - { key: "{{ namenode_container_name }}", value: "{{ (container_resolutions.results | selectattr('item.container', 'equalto', rm_container) | first).stdout }}" }
            - { key: "{{ rm_container }}",            value: "{{ (container_resolutions.results | selectattr('item.container', 'equalto', namenode_container_name) | first).stdout }}" }
          iface_ip_dict: "{{ iface_ip_list | items2dict }}"

    tags: never, setup_global_hdfs_connection

  - name: Remove connection on global hdfs with containers
    when: inventory_hostname == namenode_host
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} bash -c \
      'cp /etc/hosts {{ user_home_on_container }} \
      && sed -n '/{{ rm_container }}/!p' {{ user_home_on_container }}/hosts > {{ user_home_on_container }}/hosts.tmp; mv {{ user_home_on_container }}/hosts.tmp {{ user_home_on_container }}/hosts \
      && cat {{ user_home_on_container }}/hosts > /etc/hosts \
      && rm {{ user_home_on_container }}/hosts'"
    args:
      executable: /bin/bash
    tags: never, remove_global_hdfs_connection

  - name: Start zookeeper
    delegate_to: "{{ rm_host }}"
    run_once: yes
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} su - {{ user_info.user_name }} -c \
      'nohup /opt/zookeeper/bin/zkServer.sh start &'"
    tags: never, start_zookeeper

  - name: Setup hadoop on containers
    block:
      - name: Workers file setup
        tags: setup_hadoop, setup_hdfs
        block:
          # - name: Copy app files already on containers & Update workers file on containers
          #   shell: "{% for item in containers_info %}
          #     {% if item.host == inventory_hostname %}
          #     sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} bash -c \ 
          #     'cp -pr /opt/hadoop_files {{ bind_dir_on_container }}/ && chown -R {{ user_info.user_id }} {{ bind_dir_on_container }}/* \
          #     && {% for item in worker_list %}echo {{ item }} >> $HADOOP_CONF_DIR/workers && {% endfor %}true' && 
          #     {% endif  %}
          #     {% endfor %}true"
          #   args:
          #     executable: /bin/bash
          #   vars:
          #     worker_list: "{{ containers_info | 
          #             map(attribute='container_name') |
          #             reject('search', rm_container) | list}}"

          - name: Copy app files already on containers & Update workers file on containers
            shell: "
              {% for item in containers_info %}
                {% if item.host == inventory_hostname %}
                  sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} su - {{ user_info.user_name }} -c '\ 
                    cp -pr /opt/hadoop_files {{ bind_dir_on_container }}/ && 
                    {% for item in worker_list %}
                      echo {{ item }} >> $HADOOP_CONF_DIR/workers && 
                    {% endfor %}true
                  ' && 
                {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash
            vars:
              worker_list: "{{ containers_info | 
                      map(attribute='container_name') |
                      reject('search', rm_container) | list}}"

      - name: Prepare and copy all config files to containers
        tags: setup_hadoop, setup_hdfs
        block:
          - name: Setup configuration files to transfer
            delegate_to: localhost
            run_once: yes
            block:
              - name: Create temporary directory to store templated config files
                file:
                  path: "{{ app_tmpdir }}"
                  state: directory

              - name: Set file list to transfer
                vars:
                  start_hdfs: "{{ not global_hdfs or hdfs_mode != 'single' or app_name == global_hdfs_app_name }}"
                  start_rbf: "{{ global_hdfs and hdfs_mode == 'rbf' }}"
                  setup_spark: "{{ app_type is defined and app_type == 'spark_app' }}"
                set_fact:
                  transfer_file_dict:
                    - {
                        # remove hdfs-rbf-site if not using RBF
                        file_list: "{{ hdfs_file_list if start_rbf else hdfs_file_list | difference(['hdfs-rbf-site.xml']) }}",
                        destination: "\"$HADOOP_CONF_DIR\"",
                        template_dir: "hadoop",
                        condition: "{{ start_hdfs }}"
                      }
                    - {
                        file_list: "{{ hadoop_file_list + (['core-site.xml'] if not start_hdfs else []) }}",
                        destination: "\"$HADOOP_CONF_DIR\"",
                        template_dir: "hadoop",
                        condition: "{{ 'setup_hdfs' not in ansible_run_tags }}"
                      }
                    - {
                        file_list: "{{ spark_file_list }}",
                        destination: "\"$SPARK_CONF_DIR\"",
                        template_dir: "spark",
                        condition: "{{ setup_spark and 'setup_hdfs' not in ansible_run_tags }}"
                      }

              - name: Copy config files to master
                when: item.0.condition | default(true)
                template:
                  src: "templates/{{ item.0.template_dir }}/{{ item.1 }}"
                  dest: "{{ app_tmpdir }}/{{ item.1 }}"
                  mode: preserve
                loop: "{{ transfer_file_dict | subelements('file_list') }}"

          - name: Copy config files to hosts
            synchronize:
              src: "{{ app_tmpdir }}/"
              dest: "{{ app_tmpdir }}/"

          - name: Copy and update config files to containers
            shell: |
              {% for item in containers_info -%}
                {% if item.host == inventory_hostname -%}
                  {% set container_bind_dir = item.disk_path if item.disk_path is defined else [bind_dir, item.container_name] | join('/') -%}
                  {% for file_set in transfer_file_dict -%}
                    {% if file_set.condition | default (true) -%}
                      {% for file in file_set.file_list -%}
                        cp {{ app_tmpdir }}/{{ file }} {{ container_bind_dir }}/{{ file }} && \
                      {% endfor -%}
                    {% endif -%}
                  {% endfor -%}
                  sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} su - {{ user_info.user_name }} -c \
                  '{% for file_set in transfer_file_dict -%}
                    {% if file_set.condition | default (true) -%}
                      {% for file in file_set.file_list -%}
                        cp {{ bind_dir_on_container }}/{{ file }} {{ file_set.destination }}/{{ file }} && \
                      {% endfor -%}
                    {% endif -%}
                  {% endfor -%}true' && \
                {% endif -%}
              {% endfor -%}true
            args:
              executable: /bin/bash

          - name: Remove temporary directory in server and hosts
            file:
              path: "{{ app_tmpdir }}"
              state: absent
            delegate_to: "{{ item }}"
            run_once: yes
            with_items:
              - localhost
              - "{{ ansible_play_hosts }}"
            tags: setup_hdfs

      - name: Setup SSH connection
        tags: setup_hadoop, setup_hdfs
        block:
          - name: Update ssh known_hosts on ResourceManager/Namenode container & Move RM/NN container ssh public key
            delegate_to: "{{ rm_host }}"
            run_once: yes
            shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} su - {{ user_info.user_name }} -c \
              'ssh-keyscan -t rsa `hostname` >> ~/.ssh/known_hosts \
              && ssh-keyscan -t rsa -f $HADOOP_CONF_DIR/workers >> ~/.ssh/known_hosts \
              && cp ~/.ssh/id_rsa.pub {{ bind_dir_on_container }}/{{ rm_container }}.pub'"
            args:
              executable: /bin/bash

          ## TODO: fusion with fetch below
          - name: Prepare RM/NN container bind path variable
            when: "item.container_name == rm_container"
            set_fact:
              rm_container_bind_path: "{{ item.disk_path if item.disk_path is defined else [bind_dir, item.container_name] | join('/') }}"
            with_items:
            - "{{ containers_info }}"

          # - name: Create app directory on server for ssh public key
          #   delegate_to: localhost
          #   run_once: yes
          #   file:
          #     path: "{{ installation_path }}/apps/{{ app_name }}/"
          #     state: directory

          # - name: Fetch RM/NN container ssh public key
          #   when: rm_host == inventory_hostname
          #   synchronize:
          #     src: "{{ bind_dir }}/{{ rm_container }}/{{ rm_container }}.pub"
          #     dest: "{{ installation_path }}/apps/{{ app_name }}/{{ rm_container }}.pub"
          #     mode: pull
          #   vars:
          #     bind_path: "{{ rm_container_bind_path }}"

          - name: Create temporary app directory on hosts for ssh public key
            file:
              path: "{{ app_ssh_keys_dir }}/{{ app_name }}/"
              state: directory

          # - name: Copy RM/NN container ssh public key to hosts
          #   synchronize:
          #     src: "{{ installation_path }}/apps/{{ app_name }}/{{ rm_container }}.pub"
          #     dest: "{{ installation_path }}/apps/{{ app_name }}/{{ rm_container }}.pub"

          - name: Copy RM/NN container ssh public key to hosts
            delegate_to: "{{ rm_host }}" # this will push from rm_host to each host, i.e., a remote host to remote host copy
            synchronize:
              src: "{{ rm_container_bind_path }}/{{ rm_container }}.pub"
              dest: "{{ app_ssh_keys_dir }}/{{ app_name }}/{{ rm_container }}.pub"

          - name: Copy and append RM/NN container ssh public key to the other containers
            shell: "{% for item in containers_info %}
              {% if item.host == inventory_hostname and item.container_name != rm_container %}
              {% set container_bind_dir = item.disk_path if item.disk_path is defined else [bind_dir, item.container_name] | join('/') %}
              cp {{ app_ssh_keys_dir }}/{{ app_name }}/{{ rm_container }}.pub {{ container_bind_dir }}/{{ rm_container }}.pub && \
              sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} su - {{ user_info.user_name }} -c \
              'cat {{ bind_dir_on_container }}/{{ rm_container }}.pub >> ~/.ssh/authorized_keys \
              && rm {{ bind_dir_on_container }}/{{ rm_container }}.pub' && 
              {% endif  %}
              {% endfor %}true"
            args:
              executable: /bin/bash

      - name: Start Hadoop services
        vars:
          start_hdfs: "{{ not global_hdfs or hdfs_mode != 'single' or app_name == global_hdfs_app_name }}"
        block:
          - name: Start HDFS + YARN
            tags: setup_hadoop, setup_hdfs
            block:
              - name: Format filesystem, start HDFS and YARN (Master)
                delegate_to: "{{ rm_host }}"
                run_once: yes
                shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} su - {{ user_info.user_name }} -c \
                  ' \
                  {% if start_hdfs %}
                    cd $HADOOP_HOME && bash format_filesystem.sh && \ 
                    $HADOOP_HOME/bin/hdfs --daemon start namenode && \ 
                    {% if global_hdfs and hdfs_mode == 'rbf' %}
                      $HADOOP_HOME/bin/hdfs --daemon start dfsrouter && \ 
                    {% endif %}
                  {% endif %}
                  {% if 'setup_hdfs' not in ansible_run_tags %}
                    $HADOOP_HOME/bin/yarn --daemon start resourcemanager && \ 
                  {% endif %}
                  'true"
                args:
                  executable: /bin/bash
                async: 10800
                poll: 0
                register: start_rm_services

              - name: Start HDFS and YARN (Worker)
                shell: "{% for item in containers_info %}
                  {% if item.host == inventory_hostname and item.container_name != rm_container %}
                    sudo {{ singularity_command_alias }} exec instance://{{ item.container_name }} su - {{ user_info.user_name }} -c \
                    ' \
                    {% if start_hdfs %}
                      $HADOOP_HOME/bin/hdfs --daemon start datanode && \ 
                    {% endif %}
                    {% if 'setup_hdfs' not in ansible_run_tags %}
                      $HADOOP_HOME/bin/yarn --daemon start nodemanager' && \
                    {% endif %}
                  {% endif %}
                  {% endfor %}true"
                args:
                  executable: /bin/bash
                async: 10800
                poll: 0
                register: start_worker_services

              - name: Wait for master services to start
                async_status:
                  jid: "{{ start_rm_services.ansible_job_id }}"
                delegate_to: "{{ rm_host }}"
                run_once: yes
                register: rm_job_result
                until: rm_job_result.finished
                retries: 120
                delay: 0.5

              - name: Wait for worker services to start
                async_status:
                  jid: "{{ start_worker_services.ansible_job_id }}"
                register: worker_job_result
                until: worker_job_result.finished
                retries: 120
                delay: 0.5
                when: start_worker_services.ansible_job_id is defined
    vars:
      - containers_info: "{{ containers_info_str | replace('\n','') | replace(' ','') }}"
    tags: never

  ## Copy app files
  - name: Copy app files to container
    block:
      - name: Copy app files already on container if there was an installation
        when: "install_script != ''"
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} su - {{ user_info.user_name }} -c 'cp -pr /opt/{{ app_dir | basename }}/* {{ bind_dir_on_container }}'"
        args:
          executable: /bin/bash

      - name: Create temporary directory to store templated config files
        delegate_to: localhost
        run_once: yes
        file:
          path: "{{ app_tmpdir }}/{{ container }}"
          state: directory
          owner: "{{ user_info.user_name }}"

      - block:
          - name: Copy runtime files subdirectory in temporary directory
            copy: ## synchronize module would be faster, but it ignores the 'delegate_to' directive
              src: "apps/{{ app_dir }}/{{ runtime_files }}"
              dest: "{{ app_tmpdir }}/{{ container }}/"

          - name: Template runtime files and store in temporary directory
            when: file.state == 'file' and not file.path | regex_search('\.(jar|zip|tar|rar|gz|bz2|xz|7z|tgz)$') ## excluded extensions to template
            template:
              src: "{{ file.src }}"
              dest: "{{ app_tmpdir }}/{{ container }}/{{ runtime_files | basename }}/{{ file.path }}"
            with_filetree: "apps/{{ app_dir }}/{{ runtime_files }}/"
            loop_control:
              loop_var: file

        when: "runtime_files != ''"
        delegate_to: localhost
        run_once: yes

      - name: Create output directory in container
        when: output_dir is defined and output_dir != ""
        file:
          path: "{{ container_bind_dir }}/{{ output_dir | basename }}"
          state: directory

    tags: never, start_app, stop_app

    ## Start
  - name: Start app on container
    block:
      - name: Template app start script
        delegate_to: localhost
        template:
          src: "apps/{{ app_dir }}/{{ start_script }}"
          dest: "{{ app_tmpdir }}/{{ container }}/"
          mode: preserve

      - name: Copy app jar
        delegate_to: localhost
        when: "app_jar != ''"
        copy:
          src: "apps/{{ app_dir }}/{{ app_jar }}"
          dest: "{{ app_tmpdir }}/{{ container }}/"

      - name: Copy templated config files to remote container
        vars:
          ansible_ssh_extra_args: "-o ControlPath=~/.ansible/cp/socket-{{ inventory_hostname }}"
        synchronize:
          src: "{{ app_tmpdir }}/{{ container }}/"
          dest: "{{ container_bind_dir }}/"
          ssh_connection_multiplexing: yes
          use_ssh_args: yes

      - name: Execute start script on container
        #shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} nohup bash {{ bind_dir_on_container }}/{{ start_script | basename }} </dev/null"
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} su - {{ user_info.user_name }} -c 'source {{ singularity_env_file }} && nohup bash {{ bind_dir_on_container }}/{{ start_script | basename }} </dev/null'"
        args:
          executable: /bin/bash
        async: 10800
        poll: 0
        register: start_job

      - name: Save job id to check status later
        delegate_to: localhost
        copy:
          content: "{{ start_job.ansible_job_id }}"
          dest: "{{ jid_file }}"
          owner: "{{ user_info.user_name }}"

    tags: never, start_app

  ## Wait
  - name: Wait for app container
    block:
      - name: Read start script job id
        set_fact:
          start_job_id: "{{ lookup('file', jid_file) | trim }}"

      # Phase 1: Quick polling for fast-completing jobs (better for developing/debugging)
      - name: Wait until start script has finished - Quick poll for job completion
        async_status:
          jid: "{{ start_job_id }}"
        register: start_status
        until: start_status.finished
        retries: 120
        delay: 0.5

      # Phase 2: Slower polling if job is still running
      - name: Wait until start script has finished - Continue polling with longer intervals
        when: start_status.finished is not defined or not start_status.finished
        async_status:
          jid: "{{ start_job_id }}"
        register: start_status
        until: start_status.finished
        retries: 360  # 360 * 20 = 7200 seconds (120min - 2h)
        delay: 20

    tags: never, wait_app

  ## Stop
  - name: Stop app on container
    block:
      # Run stop script if defined
      - block:
        - name: Template app stop script
          delegate_to: localhost
          template:
            src: "apps/{{ app_dir }}/{{ stop_script }}"
            dest: "{{ app_tmpdir }}/{{ container }}/"
            mode: preserve

        - name: Copy templated config files to remote container
          vars:
            ansible_ssh_extra_args: "-o ControlPath=~/.ansible/cp/socket-{{ inventory_hostname }}"
          synchronize:
            src: "{{ app_tmpdir }}/{{ container }}/"
            dest: "{{ container_bind_dir }}/"
            ssh_connection_multiplexing: yes
            use_ssh_args: yes

        - name: Execute stop script on container
          #shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} nohup bash {{ bind_dir_on_container }}/{{ stop_script | basename }} </dev/null"
          shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} su - {{ user_info.user_name }} -c 'source {{ singularity_env_file }} && nohup bash {{ bind_dir_on_container }}/{{ stop_script | basename }} </dev/null'"
          args:
            executable: /bin/bash
          async: 3600
          poll: 0
          register: stop_job

        - name: Wait until stop script has finished
          async_status:
            jid: "{{ stop_job.ansible_job_id }}"
          register: stop_status
          until: stop_status.finished
          retries: 1200
          delay: 0.5

        when: stop_script is defined and stop_script != ""

      - name: Clean container config files from temporary directory
        delegate_to: localhost
        run_once: yes
        file:
          path: "{{ app_tmpdir }}/{{ container }}/"
          state: absent

      # Stop java snitcher
      - name: Stop java snitcher
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} su - {{ user_info.user_name }} -c \
          'tmux kill-session -t JAVA_SNITCH'"
        args:
          executable: /bin/bash
        ignore_errors: yes

      # - name: Change remaining files permissions (hadoop)
      #   # Check empty string to avoid unwanted problems if the variable is somehow wrongly defined
      #   when: "app_jar != '' and ' ' not in user_info.user_id"
      #   shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c \
      #     'cd {{ bind_dir_on_container }} \
      #     && chown -R {{ user_info.user_id }} hadoop_logs'"
      #   args:
      #     executable: /bin/bash

      # # TODO: actually transfer files from nodes to server, instead of relying on shared folders (NFS and such)
      # - name: Copy hadoop logs to output_dir
      #   when: "app_jar != '' and input_log_dir != output_log_dir"
      #   copy:
      #     src: "{{ input_log_dir }}"
      #     dest: "{{ output_log_dir }}"
      #     remote_src: yes
      #   vars:
      #     input_log_dir: "{{ container_bind_dir }}/hadoop_logs/"
      #     output_log_dir: "{{ default_bind_path }}/{{ bind_dir_name }}/{{ rm_container }}/hadoop_logs/"

      ## Manage output data
      - block:
        - name: Set output data timestamp
          when: timestamp is not defined # --> only set current timestamp if another timestamp has not been set
          set_fact:
            timestamp: "{{ now(fmt='%Y-%m-%d--%H-%M-%S') }}"

        - name: Move hadoop logs to output_dir
          when: "app_jar is defined and app_jar != ''"
          shell: "mv {{ container_bind_dir }}/hadoop_logs {{ container_bind_dir }}/{{ output_dir }}/hadoop_logs"
          args:
            executable: /bin/bash

        - block:
          - name: Create output directory on server
            delegate_to: localhost
            file:
              path: "{{ stored_output_dir }}"
              state: directory

          - name: Fetch output data from container to server
            vars:
              ansible_ssh_extra_args: "-o ControlPath=~/.ansible/cp/socket-{{ inventory_hostname }}"
            synchronize:
              src: "{{ container_bind_dir }}/{{ output_dir }}/"
              dest: "{{ stored_output_dir }}"
              mode: pull
              ssh_connection_multiplexing: yes
              use_ssh_args: yes
          vars:
            stored_output_dir: "{{ app_output_data }}/{{ app_name }}/{{ timestamp }}/{{ output_dir }}-{{ container }}"
        when: "output_dir is defined and output_dir != ''"

      # ## Clean hadoop apps
      # - block:
      #   - name: Remove hadoop config files
      #     file:
      #       path: "{{ container_bind_dir }}/{{ item }}"
      #       state: absent
      #     loop: "{{ hdfs_file_list + hadoop_file_list + spark_file_list }}"

      #   - name: Remove hadoop local logs
      #     when: "input_log_dir != output_log_dir"
      #     file:
      #       path: "{{ input_log_dir }}"
      #       state: absent
      #     vars:
      #       input_log_dir: "{{ container_bind_dir }}/hadoop_logs"
      #       output_log_dir: "{{ default_bind_path }}/{{ bind_dir_name }}/{{ rm_container }}/hadoop_logs"

      #   - name: Remove hadoop files directory in container
      #     # Check empty string to avoid unwanted problems if the variable is somehow wrongly defined
      #     when: "' ' not in bind_dir_on_container"
      #     shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c \
      #       'rm -r {{ bind_dir_on_container}}/hadoop_files'"
      #     args:
      #       executable: /bin/bash
  
      # when: "app_jar is defined and app_jar != ''"

    tags: never, stop_app

  ## Stop hadoop
  - name: Stop hadoop cluster
    block:
      - name: Stop hadoop cluster
        delegate_to: "{{ rm_host }}"
        run_once: yes
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ rm_container }} su - {{ user_info.user_name }} -c \
          'cd $HADOOP_HOME \
          {% if global_hdfs and hdfs_mode == 'rbf' %}
            && bin/hdfs --daemon stop dfsrouter \ 
          {% endif %}
          && sbin/stop-yarn.sh \
          && sbin/stop-dfs.sh \
          '"
        args:
          executable: /bin/bash
    tags: never, stop_hadoop_cluster

  # ## Clean HDFS files
  # - name: Workaround to clean global HDFS files
  #   when: "' ' not in bind_dir_on_container"
  #   shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} bash -c \
  #     'tmux kill-session -t JAVA_SNITCH && rm -r {{ bind_dir_on_container}}/hadoop_files && rm -r {{ bind_dir_on_container}}/hadoop_logs'"
  #   args:
  #     executable: /bin/bash
  #   tags: never, clean_hdfs

  - name: Stop Java Snitch
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} su - {{ user_info.user_name }} -c \
      'tmux kill-session -t JAVA_SNITCH'"
    args:
      executable: /bin/bash
    tags: never, clean_hdfs

  # # TODO: do not rely on shared folders (NFS and such) to access hadoop_logs
  # ## Set hadoop logs timestamp
  # - name: Set hadoop logs timestamp
  #   delegate_to: localhost
  #   run_once: yes
  #   shell: "mv hadoop_logs hadoop_logs_`date +%d-%m-%y--%H-%M-%S`"
  #   args:
  #     chdir: "{{ default_bind_path }}/{{ bind_dir_name }}/{{ rm_container }}"
  #     executable: /bin/bash
  #   tags: never, set_hadoop_logs_timestamp

  ## TODO: Remove app_jar conditions in these tasks (in the whole file)

  ## HDFS
  - name: Create directory on HDFS
    when: dest_path is defined and dest_path != ''
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} su - {{ user_info.user_name }} -c \
      '$HADOOP_HOME/bin/hdfs dfs -mkdir -p {{ dest_path }} \
      {% if hdfs_mode == 'rbf' %}&& $HADOOP_HOME/bin/hdfs dfsrouteradmin -add {{ dest_path }} ns-{{ global_hdfs_app_name }} {{ dest_path }}{% endif %}
      '"
    args:
      executable: /bin/bash
    tags: never, create_dir_on_hdfs

  - name: Remove file from HDFS
    when: dest_path is defined and dest_path != ''
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ container }} su - {{ user_info.user_name }} -c '$HADOOP_HOME/bin/hdfs dfs -rm -r {{ dest_path }}'"
    args:
      executable: /bin/bash
    tags: never, remove_file_from_hdfs

  - name: Upload file(s) to HDFS
    tags: never, add_file_to_hdfs
    when: dest_path is defined and dest_path != '' and origin_path is defined and origin_path != ''
    delegate_to: localhost
    vars:
      global_namenode_url: "hdfs://{{ namenode_container }}:8020"
      origin_container_path: "{{ bind_dir_on_container }}/{{ origin_path.rstrip('/') | basename }}"
    block:
      - name: Put data on HDFS
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ frontend_container }} su - {{ user_info.user_name }} -c \
          '$HADOOP_HOME/bin/hdfs dfs -put {{ origin_container_path }} {{ global_namenode_url }}/{{ dest_path }}'"
        args:
          executable: /bin/bash

  - name: Download file(s) from HDFS
    tags: never, get_file_from_hdfs
    when: dest_path is defined and origin_path is defined and origin_path != ''
    delegate_to: localhost
    vars:
      global_namenode_url: "hdfs://{{ namenode_container }}:8020"
      dest_container_path: "{{ bind_dir_on_container }}/{{ dest_path.rstrip('/') }}"
    block:
      - name: Get data from HDFS
        shell: "sudo {{ singularity_command_alias }} exec instance://{{ frontend_container }} su - {{ user_info.user_name }} -c \ 
          '$HADOOP_HOME/bin/hdfs dfs -get {{ global_namenode_url }}/{{ origin_path }} {{ dest_container_path }}'"
        args:
          executable: /bin/bash

  - name: Move data between global and local HDFS
    tags: never
    when: inventory_hostname == namenode_host
    vars:
      local_namenode_ip: "\\$(getent hosts {{ rm_container }} | awk '{print \\$1 }' | head -n 1)"  # Resolve IP for distcp, ensuring to get only one IP
      local_namenode_url: "hdfs://{{ local_namenode_ip }}:8020"
    block:
      - name: Handle data transfer between global and local HDFS
        tags: download_to_local, upload_to_global
        when:
          - ('download_to_local' in ansible_run_tags and global_input is defined and global_input != '') or
            ('upload_to_global' in ansible_run_tags  and local_input is defined and local_input != '')
        vars:
          # Set variables dynamically based on the tag
          origin: >-
            {%- if 'download_to_local' in ansible_run_tags -%}
              {{ global_input }}
            {%- else -%}
              {{ local_namenode_url }}/{{ local_input }}
            {%- endif -%}
          dest_output: >-
            {%- if 'download_to_local' in ansible_run_tags -%}
              {%- if local_output is not defined -%}
                {{ '/user/' + user_info.user_name +'/' }}
              {%- elif not local_output.startswith('/') -%}
                {{ '/user/' + user_info.user_name +'/' + local_output }}
              {%- else -%}
                {{ local_output }}
              {%- endif -%}
            {%- else -%}
              {%- if global_output is not defined -%}
                {{ '/user/' + user_info.user_name +'/' }}
              {%- elif not global_output.startswith('/') -%}
                {{ '/user/' + user_info.user_name +'/' + global_output }}
              {%- else -%}
                {{ global_output }}
              {%- endif -%}
            {%- endif -%}
          dest: >-
            {%- if 'download_to_local' in ansible_run_tags -%}
              {{ local_namenode_url }}/{{ dest_output }}/{{ global_input | basename }}
            {%- else -%}
              {{ dest_output }}/{{ local_input | basename }}
            {%- endif -%}
          replication_factor: >-
            {%- if 'download_to_local' in ansible_run_tags -%}
              {{ local_hdfs_replication }}
            {%- else -%}
              {{ global_hdfs_replication }}
            {%- endif -%}
        block:
          - name: Get requested data size
            shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} su - {{ user_info.user_name }} -c \"\\$HADOOP_HOME/bin/hdfs dfs -du -s {{ origin }} | awk '{print \\$1}' \""
            args:
              executable: /bin/bash
            register: data_size

          - name: Small data size ({{ data_size.stdout }}) --> Run get/put
            when: (data_size.stdout | int) <= (distcp_threshold | size_to_bytes)
            block:
              - name: "[Small data size ({{ data_size.stdout }} <= {{ distcp_threshold }}) --> Run get/put] Get input data"
                shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} su - {{ user_info.user_name }} -c \
                  \"\\$HADOOP_HOME/bin/hdfs dfs -get -f {{ origin }} {{ user_home_on_container }}\""
                args:
                  executable: /bin/bash

              - name: "[Small data size ({{ data_size.stdout }} <= {{ distcp_threshold }}) --> Run get/put] Put input data into target HDFS"
                shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} su - {{ user_info.user_name }} -c \
                  \"\\$HADOOP_HOME/bin/hdfs dfs -mkdir -p {{ dest | dirname }} && \\$HADOOP_HOME/bin/hdfs dfs -D dfs.replication={{ replication_factor }} -put -f {{ user_home_on_container }}/{{ origin | basename }} {{ dest }}\""
                args:
                  executable: /bin/bash

              - name: "[Small data size ({{ data_size.stdout }} <= {{ distcp_threshold }}) --> Run get/put] Remove file in temporary location"
                shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} su - {{ user_info.user_name }} -c 'rm {{ user_home_on_container }}/{{ origin | basename }}'"
                args:
                  executable: /bin/bash

          - name: Large data size ({{ data_size.stdout }} > {{ distcp_threshold }}) --> Run distcp
            when: (data_size.stdout | int) > (distcp_threshold | size_to_bytes)
            block:

              - name: Get blocks_per_chunk when mappers_assignation == 'distcp-default' or 'mapred-default' --> avoid additional calculations
                when: mappers_assignation == 'distcp-default' or mappers_assignation == 'mapred-default'
                set_fact:
                  blocks_per_chunk: "{{ '0' if mappers_assignation == 'distcp-default' else '1' }}"

              - name: Calculate blocks_per_chunk based on additional calculations
                when: blocks_per_chunk is not defined
                block:
                - name: "Get number of files and blocks to transfer"
                  shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} su - {{ user_info.user_name }} -c \
                    \"\\$HADOOP_HOME/bin/hdfs dfs -count {{ origin }} | awk '{print \\$2}' && \
                    \\$HADOOP_HOME/bin/hdfs fsck {{ origin }} | grep -o 'Total blocks.*' | awk '{print \\$4}' \""
                  args:
                    executable: /bin/bash
                  register: data_transfer_info

                - name: Calculate mappers
                  get_mappers:
                    number_of_blocks: "{{ data_transfer_info.stdout_lines[0] }}"
                    number_of_files: "{{ data_transfer_info.stdout_lines[1] }}"
                    number_of_datanodes: "{{ number_of_datanodes }}"
                    mode: "{{ mappers_assignation }}"
                  register: mappers_result

                - name: Calculate blocks_per_chunk based on additional calculations
                  set_fact:
                    blocks_per_chunk: "{{ mappers_result.mappers }}"

              - name: "[Large data size ({{ data_size.stdout }} > {{ distcp_threshold }}) --> Run distcp] Transfer data"
                shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} su - {{ user_info.user_name }} -c \
                  \"\\$HADOOP_HOME/bin/hadoop distcp -D dfs.replication={{ replication_factor }} -strategy dynamic -blocksperchunk {{ blocks_per_chunk }} {{ origin }} {{ dest }}\""
                args:
                  executable: /bin/bash

  - name: Set global HDFS replication
    tags: never, set_hdfs_replication
    when: inventory_hostname == namenode_host
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} su - {{ user_info.user_name }} -c \
      '$HADOOP_HOME/bin/hdfs dfs -setrep -R {{ replication_factor }} /'"
    args:
      executable: /bin/bash

  - name: Get HDFS filesystem
    tags: never, get_hdfs_filesystem
    when: inventory_hostname == namenode_host
    shell: "sudo {{ singularity_command_alias }} exec instance://{{ namenode_container_name }} su - {{ user_info.user_name }} -c \
      '$HADOOP_HOME/bin/hdfs dfs -ls -R -h /'"
    args:
      executable: /bin/bash