# Setup nodes
- name: Start containers in hosts
  hosts: nodes
  become: no
  gather_facts: no

  vars_files:
    - vars/main.yml
    - config/config.yml

  environment:
    BDWATCHDOG_PATH: "{{ bdwatchdog_path }}"
    SERVERLESS_PATH: "{{ serverless_containers_path }}"
    PYTHONPATH: "{{ bdwatchdog_path }}:{{ serverless_containers_path }}"

  tasks:
    - import_tasks: tasks/containers_setup/lxd_containers_setup.yml
      when: "container_engine == 'lxc'"
      tags: start_containers
      vars:
        - lxd_key_name: "lxd-{{ inventory_hostname }}"

    - name: Setup apptainer/singularity containers
      when: "container_engine == 'apptainer'"
      vars:
        - app_type: "{{ 'generic_app' if install_script is defined and install_script != '' else 'base' }}"
        - image_mapping:
            spark_app: spark_app.sif
            hadoop_app: hadoop_app.sif
            generic_app: "{{ app_dir + '.sif' if app_dir is defined }}"
            base: ubuntu_container.sif
      block:
        ## Image creation
        - include_tasks: "tasks/containers_setup/apptainer_container_image_setup.yml" # beware of the differences of 'include_tasks' vs 'import_tasks', such as tagging
          loop: "{{ reverse_image_dependencies }}"
          tags: create_app
          vars:
            - definition_mapping:
                spark_app: spark_app.def
                hadoop_app: hadoop_app.def
                generic_app: generic_app.def
                base: ubuntu_container.def
            - image_dependencies:
                spark_app: hadoop_app
                hadoop_app: base
                generic_app: base
                base: ""
            - reverse_image_dependencies: > # for example, if app_type=spark_app, the resulting list will be ['base', 'hadoop_app', 'spark_app'] to build the images in order
                  {%- set build_list = [] -%}
                  {%- set ns = namespace(current_app_type=app_type) -%}
                  {%- for _ in range(image_dependencies | length) -%}
                    {%- if ns.current_app_type -%}
                      {%- set _ = build_list.append(ns.current_app_type) -%}
                      {%- set ns.current_app_type = image_dependencies[ns.current_app_type] -%}
                    {%- endif -%}
                  {%- endfor -%}
                  {{ build_list | reverse }}

        ## Container startup
        - import_tasks: "tasks/containers_setup/apptainer_containers_cgroups_{{ container_owner }}_owned_setup.yml"
          vars:
            - container_owner: root # 'root' or 'user'
              # note: root is required at the moment to start containers with cgroups support on cgroups v1 and with specific network on both cgroups versions
            - image_file: "{{ image_mapping[app_type] }}"
            - app_directory: "apps/{{ app_dir if app_type == 'generic_app' else app_type }}"
            # Other config
            - cgroups_file: "apptainer_containers_cgroup.toml"
            - containers_info_str: >
                  {%- set containers_info=[] -%}
                  {%- for host in groups['nodes'] -%}
                    {%- for container_name in hostvars[host].containers -%}
                        {%- set container_info = dict() -%}
                        {{ container_info.update({'container_name': container_name, 'host': host, 'cpu_max': max_cpu_percentage_per_container, 'cpu_min': min_cpu_percentage_per_container, 'mem_max': max_memory_per_container, 'mem_min': min_memory_per_container }) }}
                        {%- if disk_capabilities and hostvars[host].disks|length > 0 -%}
                          {%- if create_lvm -%}
                            {{ container_info.update( {'disk': 'lvm', 'disk_path': hostvars[host].disks['lvm']['path']} ) }}
                          {%- else -%}
                            {%- set first_disk = hostvars[host].disks | first -%}
                            {{ container_info.update( {'disk': first_disk, 'disk_path': hostvars[host].disks[first_disk]['path']} ) }}
                          {%- endif -%}
                          {{ container_info.update( {'disk_max': max_diskbw_per_container, 'disk_min': min_diskbw_per_container}) }}
                        {%- endif -%}
                        {%- if power_budgeting -%}
                          {{ container_info.update({'energy_max': max_energy_per_container, 'energy_min': min_energy_per_container}) }}
                        {%- endif -%}
                        {{ containers_info.append(container_info) }}
                    {%- endfor -%}
                  {%- endfor -%}
                  {{ containers_info }}
            - containers_info: "{{ containers_info_str | replace('\n','') | replace(' ','') }}"
            ## TODO: merge the "master_container" parameter with "rm_container" as they are both used for the same purpose
            - master_container: "{{ (containers_info | first).container_name }}" # This container will act as RM/NM on distributed deployments with Hadoop/Spark

    - import_tasks: tasks/containers_setup/node_rescaler_launch.yml

# Setup server (now that nodes have been initialized)
- hosts: localhost
  become: no
  gather_facts: no

  vars_files:
    - vars/main.yml
    - config/config.yml

  environment:
    BDWATCHDOG_PATH: "{{ bdwatchdog_path }}"
    SERVERLESS_PATH: "{{ serverless_containers_path }}"
    PYTHONPATH: "{{ bdwatchdog_path }}:{{ serverless_containers_path }}"

  tasks:
    - import_tasks: tasks/launch/couchdb_launch.yml
    - import_tasks: tasks/containers_setup/node_rescaler_containers_init.yml
      tags: 
        - start_containers
        - init_node_rescaler
      vars:
        - nodes: "{{ host_list | split(',') if host_list is defined else groups['nodes'] }}"
        - containers_info_str: >
              {%- set containers_info=[] -%}
              {%- for host in nodes -%}
                {%- for container_name in hostvars[host].containers -%}
                  {%- set container_info = dict() -%}
                    {{ container_info.update({'container_name': container_name, 'host': host, 'cpu_max': max_cpu_percentage_per_container, 'cpu_min': min_cpu_percentage_per_container, 'mem_max': max_memory_per_container, 'mem_min': min_memory_per_container }) }}
                    {%- if disk_capabilities and disk_scaling and hostvars[host].disks|length > 0 -%}
                      {{ container_info.update( {'disk_read_max': max_disk_read_bw_per_container, 'disk_read_min': min_disk_read_bw_per_container, 'disk_write_max': max_disk_write_bw_per_container, 'disk_write_min': min_disk_write_bw_per_container}) }}
                    {%- endif -%}
                    {%- if power_budgeting -%}
                      {{ container_info.update({'energy_max': max_energy_per_container, 'energy_min': min_energy_per_container}) }}
                    {%- endif -%}                      
                    {{ containers_info.append(container_info) }}
                {%- endfor -%}
              {%- endfor -%}
              {{ containers_info }}
        - resources: "{{ ['cpu', 'mem'] + (['disk'] if disk_capabilities and disk_scaling else []) + (['energy'] if power_budgeting else []) }}"
        - containers_info: "{{ containers_info_str | replace('\n','') | replace(' ','') }}"