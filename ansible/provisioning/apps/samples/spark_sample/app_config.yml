## Name or list of names in case you want to create several apps with the same configuration
names: spark_sample
app_type: hadoop_app
framework: spark

## Resource configuration to load into State Database
cpu_max: 500
cpu_min: 200
mem_max: 5120
mem_min: 2048
cpu_boundary: 10
cpu_boundary_type: "percentage_of_max"
mem_boundary: 1
mem_boundary_type: "percentage_of_max"

## Only used if disk_scaling set to yes
disk_read_max: 200
disk_write_max: 200
disk_read_min: 10
disk_write_min: 10
disk_read_boundary: 10
disk_write_boundary: 10
disk_read_boundary_type: "percentage_of_max"
disk_write_boundary_type: "percentage_of_max"

## Only used if power_budgeting set to yes
energy_max: 50
energy_min: 10
energy_boundary: 5
energy_boundary_type: "percentage_of_max"

## The indicated files should be in the same directory as this configuration file
start_script: start.sh
stop_script: stop.sh
app_jar: app_jar.jar

## Directory in the container where the app should store the data to be persisted
output_dir: output_dir